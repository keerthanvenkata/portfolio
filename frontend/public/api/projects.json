[
  {
    "id": "qfi-capital",
    "title": "QFI Research Capital",
    "role": "Founding Engineer & Consultant",
    "description": "Algorithmic trading platform with mid‑frequency execution, real‑time analytics, risk management, and modular architecture. Built institutional‑grade data and execution pipelines with foundations for portfolio management and future AI‑driven signal generation.",
    "contribution": "Architected and led the initial build for four months (co‑founder → consultant).",
    "contributionBullets": [
      "Designed the event‑driven architecture and core trading domain model.",
      "Implemented real‑time WebSocket ingestion and Kafka producers for market data.",
      "Built Kafka consumers for ETL aggregation (multi‑interval OHLCV) into InfluxDB.",
      "Provisioned PostgreSQL for orders/positions/config; Redis for quotes/sessions.",
      "Integrated Kite Connect OAuth, token lifecycle, and throttled order execution.",
      "Exposed FastAPI REST endpoints for orders, positions, health, and data control.",
      "Set up observability (structured logs/metrics) and Dockerized local/staging envs."
    ],
    "tech": [
      "Python",
      "C++",
      "PostgreSQL",
      "InfluxDB",
      "Docker",
      "Kafka",
      "Redis",
      "Kite Connect"
    ],
    "link": "https://qficapital.in",
    "embedSite": "https://qficapital.in",
    "status": "Live",
    "images": [
      "projects/qfi/qfi.png"
    ],
    "video": null,
    "videoPoster": null,
    "highlights": [
      "Mid‑frequency algorithmic trading with real‑time analytics and execution.",
      "Sub‑second Kafka streaming pipelines enabling timely signals and decisions.",
      "Institutional‑grade automation with risk controls and portfolio analytics.",
      "Improved reliability and latency through resilient services and observability.",
      "Backtesting and simulation groundwork for confident strategy validation.",
      "Multi‑asset capability (equities/derivatives) via a unified data plane.",
      "Co‑founder leadership: tech vision, mentoring, and early engineering hiring."
    ],
    "relatedProjects": [
      "trading-bot"
    ],
    "relatedPosts": [
      "startup-journey"
    ],
    "featured": true,
    "kind": "project"
  },
  {
    "id": "property-appraisal",
    "title": "Automated Property Appraisal Extraction",
    "role": "SDE Applied AI at Adaequare",
    "description": "Automated PDF report extraction that converts unstructured appraisal PDFs into structured JSON using a dual OCR + LLM pipeline.",
    "contribution": "Architected and built a modular dual‑pipeline (OCR + LLM) system end‑to‑end.",
    "contributionBullets": [
      "Implemented PDF splitting (Poppler) and image preprocessing (OpenCV).",
      "Integrated LayoutParser/Detectron2 for page layout and region extraction.",
      "Built OCR pipeline (Tesseract) with cleaning and deduplication.",
      "Persisted page‑level artifacts to JSONL for traceability and reprocessing.",
      "Developed LLM extraction with chunking, prompt templates, and merge/normalize.",
      "Exposed FastAPI routers to orchestrate OCR/LLM flows; added Streamlit dashboard.",
      "Centralized logging/config; standardized outputs for downstream analytics."
    ],
    "tech": [
      "FastAPI",
      "Python",
      "Poppler",
      "OpenCV",
      "Detectron2",
      "LayoutParser",
      "Tesseract",
      "GPT-4",
      "Streamlit",
      "JSONL",
      "PostgreSQL"
    ],
    "status": "Production",
    "images": [
      "projects/property-appraisal/arch.jpg",
      "projects/property-appraisal/sample.jpg",
      "projects/property-appraisal/ss.jpg"
    ],
    "video": "https://www.loom.com/embed/0c90f480866644fc9677b4d7feaeb4af",
    "videoPoster": "projects/property-appraisal/videoframe.png",
    "highlights": [
      "Automates 10,000+ appraisal PDFs/year; ~300 hours/month saved; faster customer turnaround.",
      "Dual‑pipeline architecture (OCR + LLM) with clean separation for maintainability.",
      "High‑accuracy extraction via preprocessing, layout parsing, and normalization.",
      "API orchestration (FastAPI) and dashboard (Streamlit) for review and export.",
      "JSONL artifact trail for traceability, debugging, and repeatable reprocessing.",
      "Production‑ready design with centralized logging/config and extensible NLP pipeline."
    ],
    "relatedProjects": [
      "tax-roll-pipeline"
    ],
    "relatedPosts": [
      "fastapi-practices"
    ],
    "featured": true,
    "kind": "project"
  },
  {
    "id": "tax-roll-pipeline",
    "title": "Automated Tax Roll Processing Pipeline",
    "role": "SDE Applied AI at Adaequare",
    "description": "Enterprise data transformation system automating tax roll data matching across 3,000+ counties. A hybrid AI‑assisted two‑layer matching approach maps diverse county formats to standardized schemas, reducing analyst workload while preserving high accuracy.",
    "contribution": "Designed and delivered the hybrid AI‑assisted transformation platform end‑to‑end.",
    "contributionBullets": [
      "Two‑layer matching: Heuristics (token fuzzy, Jaccard, datatype scoring) + Gemini semantic matching on sampled values.",
      "Experimented with different matching algorithms and models to improve accuracy and recall.",
      "Built a feedback loop where analyst corrections improve future processing.",
      "Exposed FastAPI routers to orchestrate OCR/LLM flows as well as ETL pipeline operations.",
      "Target‑based architecture with multi‑source transformations and dependency tracking.",
      "Operator‑driven ETL engine: copy, trim, concat, static, arithmetic, and custom functions with full auditability.",
      "Preview mode for rapid QA; seconds vs. minutes for full ETL runs.",
      "React frontend for job management: uploads/merging, status tracking, target‑based review; localStorage + DB sync.",
      "Similarity score pipeline (0–1) integrated DB → API → UI as an analyst decision signal."
    ],
    "tech": [
      "Python 3.11",
      "FastAPI",
      "PostgreSQL (Azure)",
      "SQLAlchemy",
      "Pandas",
      "Google Gemini 2.5",
      "React 18",
      "TypeScript",
      "Vite",
      "React Query",
      "Node.js",
      "Docker",
      "OpenAPI"
    ],
    "status": "Production",
    "images": [
      "projects/tax-roll-pipeline/ss1.png",
      "projects/tax-roll-pipeline/ss2.png",
      "projects/tax-roll-pipeline/ss3.png",
      "projects/tax-roll-pipeline/ss7.png",
      "projects/tax-roll-pipeline/ss9.png"
    ],
    "highlights": [
      "Significant reduction in analyst review time; higher throughput for operations.",
      "70%+ auto‑acceptance using AI-assisted matching without manual intervention.",
      "100% accuracy, 78% recall and an F1 score of 88%.",
      "Scalable architecture for 3,000+ counties.",
      "Production‑ready POC: OpenAPI docs, Docker‑ready, PII masking and sample limiting."
    ],
    "relatedProjects": [
      "property-appraisal"
    ],
    "featured": false,
    "kind": "project"
  },
  {
    "id": "trading-bot",
    "title": "Weekend Trading Bot",
    "description": "Scrappy bot built over a weekend to test strategies.",
    "tech": [
      "Python",
      "Pandas"
    ],
    "details": "Uses technical indicators and simple rules.",
    "highlights": [
      "Real-time data processing",
      "Backtesting framework"
    ],
    "images": [],
    "featured": false,
    "kind": "experimental"
  },
  {
    "id": "cli-tool",
    "title": "CLI Tool for Data Cleaning",
    "description": "Utility for quick CSV transformations.",
    "tech": [
      "Python",
      "Click"
    ],
    "details": "Handles repetitive CSV cleaning tasks.",
    "highlights": [
      "Quick transformations",
      "Batch processing"
    ],
    "images": [],
    "featured": false,
    "kind": "experimental"
  }
]