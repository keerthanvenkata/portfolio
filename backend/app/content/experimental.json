[
  {
    "id": "q-rate",
    "title": "Q-Rate",
    "description": "Loyalty and verification system for cafes that eliminates social friction in review collection and reduces fraud risk. Built based on existing loyalty programs, with WhatsApp integration, digital stamp cards, and point-based redemption. Currently in active development with a clear roadmap from verified reviews (V0) to a unified discovery platform (V2).",
    "tech": ["Python", "FastAPI", "PostgreSQL", "React", "Vite", "TypeScript", "PWA", "WhatsApp Business API", "Docker"],
    "details": "I'm building Q-Rate as a loyalty platform for Hyderabad's cafe market, inspired by existing loyalty programs but designed to solve specific pain points I've observed. The system includes customer and staff PWAs, an admin portal for cafe owners, and WhatsApp Business API integration for seamless customer engagement. The goal is to make it easy for staff to enroll customers and manage loyalty points while providing analytics and fraud prevention. This is something I'm actively working on and trying to build into a real product.",
    "highlights": [
      "WhatsApp Business API integration for zero-friction customer engagement",
      "Dual PWA architecture: Separate customer and staff applications",
      "Digital stamp cards and point-based redemption system",
      "Admin portal with analytics, loyalty ratio configuration, and staff performance tracking",
      "Multi-phase roadmap: From verified reviews to unified discovery platform",
      "Built based on existing loyalty programs with improvements for the cafe market"
    ],
    "link": "https://github.com/keerthanvenkata/q-rate",
    "collaboration": {
      "seeking": true,
      "types": ["Development", "Technical Architecture", "Business Strategy", "Product Management", "Sales & Marketing"],
      "contact": "/contact"
    },
    "service": {
      "available": false,
      "description": ""
    },
    "relatedPosts": ["startup-journey"],
    "images": [],
    "featured": false,
    "kind": "experimental"
  },
  {
    "id": "document-data-extraction",
    "title": "Document Data Extraction",
    "description": "Generalized document extraction framework built as an attempt to abstract and generalize the property appraisal extraction project. Inspired by that work, this framework features modular architecture with separate OCR and LLM pipelines for document processing.",
    "tech": ["Python", "FastAPI", "Streamlit", "Tesseract", "LayoutParser", "Detectron2", "Poppler", "LLM"],
    "details": "After building the property appraisal extraction system, I wanted to see if I could generalize the approach for other document types. This project was my attempt to abstract and generalize that work into a reusable framework. The initial idea was to make it easily customizable for different applications, though I didn't end up focusing heavily on that customization aspect. Instead, I focused more on the core extraction pipelines - separate OCR and LLM modules that can be swapped or extended. It's a learning project that helped me understand how to structure document processing systems.",
    "highlights": [
      "Built to abstract and generalize the property appraisal extraction project",
      "Modular OCR and LLM pipelines for flexible document processing",
      "FastAPI REST endpoints for programmatic access",
      "Streamlit dashboard for interactive data review and export",
      "Inspired by real-world document extraction needs"
    ],
    "link": "https://github.com/keerthanvenkata/document_data_extraction",
    "collaboration": {
      "seeking": false,
      "types": [],
      "contact": "/contact"
    },
    "service": {
      "available": true,
      "description": "This framework can be customized for specific document types and extraction requirements. Available for custom development projects."
    },
    "relatedProjects": ["property-appraisal"],
    "images": [],
    "featured": false,
    "kind": "experimental"
  },
  {
    "id": "trading-and-backtesting-bot",
    "title": "Trading and Backtesting Bot",
    "description": "Internal experimental tool used while building QFI Research Capital. Backtesting and strategy-validation sandbox aligned with the same data and execution stack (Kafka, InfluxDB, Kite Connect) that informed the main platform. No public link—internal R&D only.",
    "tech": ["Python", "PostgreSQL", "InfluxDB", "Docker", "Kafka", "Kite Connect"],
    "details": "While working on QFI we built this bot as an internal sandbox to verify quantitative assumptions, test strategies, and validate backtesting methodologies before and alongside the main platform. It shares the same event-driven ideas and stack: real-time market data via Kafka, OHLCV aggregation into InfluxDB, and execution via Kite Connect. The goal was to run experiments and understand market dynamics without affecting production, and to inform design decisions for the institutional platform. That’s why it stays unlinked—it was internal tooling, not a shipped product.",
    "highlights": [
      "Internal R&D tool used during QFI Research Capital; no public deployment or link",
      "Backtesting and simulation for strategy validation, aligned with QFI’s production stack",
      "Same data plane: Kafka, InfluxDB, PostgreSQL, Kite Connect",
      "Real-time market data processing and execution sandbox for quantitative experiments"
    ],
    "collaboration": {
      "seeking": false,
      "types": [],
      "contact": "/contact"
    },
    "service": {
      "available": false,
      "description": ""
    },
    "relatedProjects": ["qfi-capital"],
    "images": [],
    "featured": false,
    "kind": "experimental"
  }
]


